# Auto Scaling

## EC2 Auto Scaling Overview

- Automatically launch and terminate instances

- Maintain target number of instances
  - If instance fails its health check
    - launch another instance to replace it

- Using Metrics
  - cloudwatch can monitor
    - CPU
    - number of connections
    - disk IO
  - when metric is hit can trigger launching or terminating instances

- Can be used in combination with a load balancer

- An **Auto Scaling Group** is created from a **Launch Configuration / Template**
- **Launch Configuration / Template** specifies what type of instances the Auto Scaling Group will automatically create

---

### Exercise - Set Up Auto Scaling with a Load Balancer

From EC2 management console
- Create launch configuration for auto scaling group
  - give IAM role for S3 full access
  - Paste user data that gives instance a name
  - web access security group - SSH, HTTP

- create auto scaling group
  - give name
  - choose launch configuration
  - group size - 2
  - choose 2 subnets
  - configure scaling policies
    - between 2 and 4 instances
    - based on CPU - 70 (70%)

- After Auto Scaling Group creation explore tabs
  - activity history
  - updating scaling policies
  - can schedule a scaling event

- Create Application Load Balancer
  - specify subnets based on where instances were launched
    - or all subnets
  - Add target group TG1
  - don't need to register targets
  - want to connect to auto scaling group

- in autoscaling group
  - select target group - TG1
    - this will connect it to load balancer
  - Health Check Type - EC2

  - can check status of instances attached to auto scaling group

- get dns name from load balancer
  - can cycle between instances

---

### Exercise - Auto Scaling Group - Scaling Policies

- Add a scaling policy
  - step scaling policy
    - name Maintain load
    - create an alarm
      - execute policy when CPU utilization is 70% or greater for 5 minutes
      - add 1 instance
  - remove target tracking scaling policy

- Generate load
  - on each instance
    - ssh into an instance
    - install stress utility
      - `sudo amazon-linux-extras install epel -y`
      - `sudo yum install stress -y`

    - run stress command
      - `stress -c 8`

- In auto scaling groups console > monitoring
  - observe cpu usage
  - when both instances hit above threshold watch for new instance coming online
- go to activity history
  - view logged activity

- terminate an instance
  - watch another one come online to replace it

Clean Up
- Delete 
  - Auto Scaling Group
  - launch configuration
  - load balancer
  - target group
  - EC2 instances

---

## Launch Configuration and Launch Templates

### Launch configuration
- Attached to an Auto Scaling Group
- Specifies what kind of instance auto scaling group launches

- Can specify anything you would when creating an EC2 instance
  - AMI
  - instance type
  - security group
  - IAM roles
  - other settings...

- Launch configurations cannot be modified after creation
  - Can instead copy and modify copy

---

### Launch Templates

- similar options to launch configurations
- under advanced details can configure many more config options

- Can create a Launch Template from an existing instance
  - actions > create template from instance

- Can configure **fleet composition**
  - mix spot instances with on-demand instances

---

## Auto Scaling Health Checks

- Auto Scaling uses the EC2 instance **status checks**
  - if instance has instance state other than *running* it will terminate the instance and replace it

- System status check
- Instance status checks

### Elastic Load Balancer (ELB) Health Checks

- Elastic Load Balancer performs its own **ELB health checks** as well as performs the **EC2 status checks**
  - if instance does not pass both checks it will terminate and replace it
  - Auto Scaling Group regularly pings ELB to know which instances available

- Recommended to use **ELB Health Checks** option with your Auto Scaling Group
  - otherwise ELB may take an instance offline if unhealthy and Auto Scaling will not know that it has been taken offline

---

## Auto Scaling Termination Policies

- ASG needs to terminate an instance in response to an event
- ASG realizes you don't need the capacity anymore

- When creating/editing an ASG
  - can set a termination policy

- Defult Termination Policy
  - Determining Which instance to terminate
    - AZ with most instances
    - try to balance the amount of on-demand or spot instances to match your desired amount
    - terminate the instance that uses the oldest launch template or configuration
    - remove the instance closes to the next billing hour

- When creating/editing an ASG
  - instance protection - determine which instances to not terminate
  - Supended Processes
    - skip certain auto scaling processes, ie. Termination, ReplaceUnhealthy

---

## Cross-Zone Load Balancing

- Allows your ELB to distribute traffic across AZs based on how many instances in each AZ.
- Allows for distributing equal amount of load to each instance

[see slide diagram]

Application Load Balancer
- enabled by default

Network Load Balancer
- disabled by default

---

### Exercise - Set Up Auto Scaling Group

- Create Launch Configuration
  - S3 full access IAM role
  - paste in user data
    - shows random name for each instance
  - web access security group

- Create Auto Scaling Group
   - 3 instances
   - split across 2 AZs

Clean Up
- Keep set up in place for next 2 labs

---

### Exercise - Network Load Balancer Cross-Zone

- Create Network Load Balancer
  - internet facing
  - add in AZs where instances live
  - Create new Target Group - TG1
    - Healthy threshold - 2
    - Register all targets

- Currently Cross Zone Load Balancing is disabled

- Visit the DNS name of the load balancer
- Try visiting in multiple private browsing windows

- Enable cross zone load balancing

- Visit again in private browsing windows

---

### Exercise - Aplication Load Balancer

- Delete NLB and Target Group
- Create ALB
  - HTTP
  - select AZs
  - Create another target group
    - protocol is HTTP - allows it to work for ALB

- Copy DNS name and visit in browser
- can view cycling from single browser
- Cross zone load balancing
  - always enabled for ALB
  - can't disable

Clean up
- delete
  - ALB
  - 3 instances

---

## ELB Sticky Sessions

Sticky Sessions
- A client is bound to one instance by the load balancer
- helpful if session state is stored on the instance
- stays for the lifetime of the session

How does it work?
- ELB generates a cookie and sends to the client to store
- cookie associates client with an instance
  - cookie sent with client's subsequent requests
  - Load Balancer reads cookie and sends to proper instance

- Cookies can be set to expire

If instance goes offline
  - load balancer directs client to available instance
  - sends client new cookie

ALB
  - supports sticky sessions
  - sends cookie with 'AWSALB' name
  - app generated cookies not supported

NLB
  - does not supports sticky sessions
  - does not support application generated cookies

CLB
  - supports sticky sessions
  - supports app generated cookies

--- 


## ALB Listeners and SSL TLS


- Load Balancer listeners must listen on unique ports
- Can repeat the same port across different target groups
  - those target groups are pointed to from different listeners

### Exercise

#### Summary
- Create multiple listeners
- Have target groups behind listeners
- Set up SSL/TLS certificates

#### Steps
- in AWS certificate manager console
  - request public cert for main domain name
  - email validation

  - request public cert for `shop.<domain>` subdomain

  - validate certificates in confirmation emails

- Create launch configuration / template
  - S3 full access
  - user data to give each instance random name on index.html
  - SSH, HTTP, HTTPS security group

- Create Auto Scaling Group
  - 4 instances
  - no scaling policy needed

- Create Application Load Balancer
  - 2 listeners
    - HTTP
    - HTTPS
  - choose a certificate from ACM
    - `shop.<domain>`
  - create target grouop TG1
    - healthy threshold - 2

- Name instances

- Create 2 more target groups
  - TG2 - HTTP
    - healthy threshold - 2
  - TG3 - HTTPS (wont actually add SSL cert to instance. just shown for example)
    - healthy threshold - 2

- Add instances to target groups
  - TG1 - instance 1 & 2
  - TG2 - instance 2 & 3
  - TG3 - instance 4

- In Load Balancer
- for HTTPS
  - view/edit certificates
    - make `<domain>` the default cert
    - add `<domain>`
    - add for `shop.<domain>`

- edit rules for HTTPS
  - add rule with host header
    - if `shop.<domain>` forward to TG2
    - default forward to TG1

- edit rule for HTTP
  - forward all to TG3

- Go to Route 53 Console
- in hosted zone
  - create a record set for zone apex (no subdomain)
    - alias - our application load balancer
  - created a record set for `shop.<domain>`
    - alias - our application load balancer

- Visit `https://<domain>`
  - should hit instance 1 and 2

- Visit `https://shop.<domain>`
  - should hit instance 2 and 3

Clean up
- for hosted zone
  - remove A Records we just created pointing to ALB
- Delete
  - load balancer
  - target
  - Auto scaling group
  - launch configuration
  - instances

---

## Public ALB with Private Instances and Security Groups

- PublicALB security groups
  - inbound from anywhere
    - HTTP
  - outbound
    - HTTP to PrivateEC2 only

- PrivateEC2 security group
  - inbound
    - HTTP from PublicALB
  - outbound
    - HTTP to anywhere via the NAT Gateway

---

connect public load balancers to private EC2 instances
<br>
[https://aws.amazon.com/premiumsupport/knowledge-center/public-load-balancer-private-ec2/](https://aws.amazon.com/premiumsupport/knowledge-center/public-load-balancer-private-ec2/)

---

### Exercise

- Create 2 Private subnets
  - In 2 separate AZs
  - proper CIDR blocks 

- Create custom route table
- Associate 2 private subnets to route table

- Create NAT Gateway
  - in public subnet
  - Give Elastic IP address

- In Route Table
  - Add entry
    - pointing 0.0.0.0/0 to NAT Gateway

- Set up security groups
  - Create PublicALB
    - add name in description
  - Create Private EC2
    - add name in description

  - Add rules
    - PublicALB
      - inbound from anywhere
        - HTTP
      - outbound
        - HTTP to PrivateEC2 only

    - PrivateEC2 security group
      - inbound
        - HTTP from PublicALB
      - outbound
        - HTTP to anywhere via the NAT Gateway

- Create Launch Template
  - key pair
  - S3 Acceess
  - user data
  - add security groups
    - PrivateEC2
    - SSH

- Create Auto Scaling Group for private instances
  - 4 instances
  - in **private** subnets A and B

- Create Application Load Balancer
  - protocol HTTP
  - connecting to **public** subnets in AZ A and B
  - security groups
    - PublicALB
    - SSH
  - Add Target group TG1
    - health threshold - 2
    - add instances to TG1

- In ASG
  - Add target group - TG1

- In Load balancer
  - In target groups
    - wait for instances to come online - show as healthy

- Get the DNS domain for the ALB and test in browser
  - with ALB we can cycle through instances from a single user agent

#### How does it work?
- The ALB has been connected to **public** subnets in AZ A and B
  - This deploys nodes in those public subnets that can then direct traffic to private instances
- The ALB has TG1 set as the target to direct traffic to the private instances

- The ASG is configured to use TG1 as its target group

Clean Up
- Delete
  - NAT gateway
  - Elastic IP (after NAT gateway deletes)
  - Load balancer
  - target group
  - ASG
  - launch configuration
  - instances

---












